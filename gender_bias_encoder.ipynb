{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Gender bias w.r.t occupation in contextual embeddings","metadata":{}},{"cell_type":"code","source":"!pip install torch transformer-lens datasets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip uninstall numpy -y\n!pip install numpy==1.26.4\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#run this block if u want to load bert base\nfrom transformer_lens import HookedEncoder\nimport torch\n\ndevice=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel2 = HookedEncoder.from_pretrained(\"google-bert/bert-base-uncased\", device=\"cuda\", move_to_device=True)\nmodel2=model2.to(device)\nmodel2.eval()\n\n\n# text = \"The girl is an engineer.\"\n# tokens, token_type_ids, attn_mask = model2.to_tokens(text, move_to_device=True)\n\n# logits, cache = model2.run_with_cache(\n#     tokens,\n#     token_type_ids=token_type_ids,\n#     one_zero_attention_mask=attn_mask,\n#     return_type=\"logits\",\n# )\n# print(list(cache.keys())[:30])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformer_lens import HookedEncoder\nimport torch\ndevice=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = HookedEncoder.from_pretrained(\"google-bert/bert-large-uncased\", device=\"cuda\", move_to_device=True)\nmodel=model.to(device)\nmodel.eval()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T16:52:32.356577Z","iopub.execute_input":"2026-01-01T16:52:32.357218Z","iopub.status.idle":"2026-01-01T16:53:02.896984Z","shell.execute_reply.started":"2026-01-01T16:52:32.357187Z","shell.execute_reply":"2026-01-01T16:53:02.896204Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# text = \"The girl is an engineer.\"\n# tokens, token_type_ids, attn_mask = model.to_tokens(text, move_to_device=True)\n\n# logits, cache = model.run_with_cache(\n#     tokens,\n#     token_type_ids=token_type_ids,\n#     one_zero_attention_mask=attn_mask,\n#     return_type=\"logits\",\n# )\n# print(list(cache.keys())[:30])","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def unembed(resid):  # resid: [batch, pos, d_model]\n#     return resid @ model.W_U + model.b_U  # -> [batch, pos, d_vocab]\n\n# # 1) Find candidate residual-stream activations\n# resid_keys = [k for k in cache.keys() if \"resid\" in k or \"embed\" in k]\n# for resid_key in resid_keys:\n#     print(f\"\\\"{resid_key}\\\",\")    \n\n\n","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# keys_to_probe = [\n# ]\n# for key in resid_keys:\n#     if \"hook_normalized_resid_post\" in key:\n#         keys_to_probe.append(key)    \n# print(keys_to_probe)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# layer_logits = {}\n# with torch.no_grad():\n#     for k in keys_to_probe:\n#         resid = cache[k]\n#         layer_logits[k] = unembed(resid)              # logits per layer\n#         # probs = layer_logits[k].softmax(dim=-1)     # optional","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn.functional as F\nprompt = \"[MASK] is an engineer.\"\n\n# Tokenize (if your version supports move_to_device here, use it; else .to(device) manually)\ntokens, token_type_ids, attn_mask = model.to_tokens(prompt)\ntokens = tokens.to(device)\nif token_type_ids is not None: token_type_ids = token_type_ids.to(device)\nif attn_mask is not None: attn_mask = attn_mask.to(device)\n\n# Forward pass: logits shape = (batch, pos, d_vocab)\nlogits, cache = model.run_with_cache(\n    tokens,\n    token_type_ids=token_type_ids,\n    one_zero_attention_mask=attn_mask,\n    return_type=\"logits\",\n)\n\n# 1) Identify the position you're analyzing\nmask_id = model.tokenizer.mask_token_id\nmask_pos = (tokens[0] == mask_id).nonzero(as_tuple=False).item()\n\n# 2) Get the distribution at that position\nmask_logits = logits[0, mask_pos, :]                # [d_vocab]\nmask_probs  = F.softmax(mask_logits, dim=-1)        # [d_vocab]\n\n# 3) Probability of particular candidate tokens (note: BERT WordPiece tokens)\nshe_id = model.tokenizer.convert_tokens_to_ids(\"she\")\nhe_id  = model.tokenizer.convert_tokens_to_ids(\"he\")\n\nprint(\"P(she | context) =\", float(mask_probs[she_id]))\nprint(\"P(he  | context) =\", float(mask_probs[he_id]))\n\n# 4) Or just inspect top-k predictions at that position\ntopk = torch.topk(mask_probs, k=10)\ntop_tokens = model.tokenizer.convert_ids_to_tokens(topk.indices.tolist())\nprint(list(zip(top_tokens, topk.values.tolist())))\n\nprint(\"logit(she | context) =\", float(mask_logits[she_id]))\nprint(\"logit(he  | context) =\", float(mask_logits[he_id]))\n\n# 4) Or just inspect top-k predictions at that position\ntopk = torch.topk(mask_logits, k=10)\ntop_tokens = model2.tokenizer.convert_ids_to_tokens(topk.indices.tolist())\nprint(list(zip(top_tokens, topk.values.tolist())))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def unembed(resid):  # resid: [batch, pos, d_model]\n    return resid @ model.W_U + model.b_U  # -> [batch, pos, d_vocab]\n\nlayer_keys = [\"embed.hook_embed\"] + [f\"blocks.{l}.hook_resid_post\" for l in range(model.cfg.n_layers)]+ [f\"blocks.{l}.hook_normalized_resid_post\" for l in range(model.cfg.n_layers)] + [\"mlm_head.ln.hook_normalized\"]\nhe_id = model.tokenizer.convert_tokens_to_ids(\"he\")\nfor k in layer_keys:\n    resid = cache[k]                               # [batch, pos, d_model]\n    layer_logits = unembed(resid)[0, mask_pos, :]   # [d_vocab]\n    layer_probs  = F.softmax(layer_logits, dim=-1)\n\n    print(k, \"P(she)=\", float(layer_probs[she_id]), \"P(he)=\", float(layer_probs[he_id]))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn.functional as F\nprompt = \"The [MASK] is an engineer.\"\n\n# Tokenize (if your version supports move_to_device here, use it; else .to(device) manually)\ntokens, token_type_ids, attn_mask = model.to_tokens(prompt)\ntokens = tokens.to(device)\nif token_type_ids is not None: token_type_ids = token_type_ids.to(device)\nif attn_mask is not None: attn_mask = attn_mask.to(device)\n\n# Forward pass: logits shape = (batch, pos, d_vocab)\nlogits, cache = model.run_with_cache(\n    tokens,\n    token_type_ids=token_type_ids,\n    one_zero_attention_mask=attn_mask,\n    return_type=\"logits\",\n)\n\n# 1) Identify the position you're analyzing\nmask_id = model.tokenizer.mask_token_id\nmask_pos = (tokens[0] == mask_id).nonzero(as_tuple=False).item()\n\n# 2) Get the distribution at that position\nmask_logits = logits[0, mask_pos, :]                # [d_vocab]\nmask_probs  = F.softmax(mask_logits, dim=-1)        # [d_vocab]\n\n# 3) Probability of particular candidate tokens (note: BERT WordPiece tokens)\nshe_id = model.tokenizer.convert_tokens_to_ids(\"she\")\nhe_id  = model.tokenizer.convert_tokens_to_ids(\"he\")\n\nprint(\"P(she | context) =\", float(mask_probs[she_id]))\nprint(\"P(he  | context) =\", float(mask_probs[he_id]))\n\n# 4) Or just inspect top-k predictions at that position\ntopk = torch.topk(mask_probs, k=10)\ntop_tokens = model.tokenizer.convert_ids_to_tokens(topk.indices.tolist())\nprint(list(zip(top_tokens, topk.values.tolist())))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def unembed(resid):  # resid: [batch, pos, d_model]\n    return resid @ model.W_U + model.b_U  # -> [batch, pos, d_vocab]\n\nlayer_keys = [\"embed.hook_embed\"] + [f\"blocks.{l}.hook_resid_post\" for l in range(model.cfg.n_layers)]+ [f\"blocks.{l}.hook_normalized_resid_post\" for l in range(model.cfg.n_layers)] + [\"mlm_head.ln.hook_normalized\"]\nhe_id = model.tokenizer.convert_tokens_to_ids(\"he\")\nfor k in layer_keys:\n    resid = cache[k]                               # [batch, pos, d_model]\n    layer_logits = unembed(resid)[0, mask_pos, :]   # [d_vocab]\n    layer_probs  = F.softmax(layer_logits, dim=-1)\n\n    print(k, \"P(she)=\", float(layer_probs[she_id]), \"P(he)=\", float(layer_probs[he_id]))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# experiment - if the unembedding has gender bias","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\n\nd_model = model.cfg.d_model\nhe_id   = model.tokenizer.convert_tokens_to_ids(\"he\")\n\ndef unembed(x):\n    return x @ model.W_U + model.b_U  # x: [batch, pos, d_model] -> [batch, pos, d_vocab] [web:89]\n\nmask_id  = model.tokenizer.mask_token_id\nmask_pos = (tokens[0] == mask_id).nonzero(as_tuple=False).item()\n\n# True scalar targets at the [MASK] position\nwith torch.no_grad():\n    true_logit_he = logits[0, mask_pos, he_id].item()\n    true_prob_he  = F.softmax(logits[0, mask_pos, :], dim=-1)[he_id].item()\n\n# Candidate activations: only tensors shaped [batch, pos, d_model]\ncands = [\n    k for k, v in cache.items()\n    if isinstance(v, torch.Tensor) and v.ndim == 3 and v.shape[-1] == d_model\n]\n\nlogit_errs = []\nprob_errs  = []\n\nwith torch.no_grad():\n    for k in cands:\n        approx_logits = unembed(cache[k])                # [batch, pos, d_vocab]\n        approx_logit_he = approx_logits[0, mask_pos, he_id].item()\n\n        # For probability, softmax at that position\n        approx_prob_he = F.softmax(approx_logits[0, mask_pos, :], dim=-1)[he_id].item()\n\n        logit_errs.append((abs(approx_logit_he - true_logit_he), k))\n        prob_errs.append((abs(approx_prob_he  - true_prob_he ), k))\n\nlogit_errs.sort()\nprob_errs.sort()\n\nprint(\"True logit(he):\", true_logit_he)\nprint(\"Top-10 best matches for logit(he):\")\nfor err, k in logit_errs[:10]:\n    print(f\"{err:.6g}\", k)\n\nprint(\"\\nTrue P(he):\", true_prob_he)\nprint(\"Top-10 best matches for P(he):\")\nfor err, k in prob_errs[:10]:\n    print(f\"{err:.6g}\", k)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# W_U: [d_model, d_vocab]  [web:89]\nW_U = model.W_U.detach()\n\n# Each token corresponds to a column vector W_U[:, token_id]\ncol_norms = torch.linalg.norm(W_U, dim=0)          # [d_vocab]\ncol_norms_np = col_norms.cpu().numpy()\n\n# Summary stats\nmn = float(col_norms.min().item())\nmx = float(col_norms.max().item())\nmean = float(col_norms.mean().item())\nstd = float(col_norms.std(unbiased=False).item())\n\nprint(\"Unembed column-norm stats:\")\nprint(\"min :\", mn)\nprint(\"max :\", mx)\nprint(\"mean:\", mean)\nprint(\"std :\", std)\n\n# (Optional) identify tokens with min/max norms\nmin_id = int(torch.argmin(col_norms).item())\nmax_id = int(torch.argmax(col_norms).item())\nprint(\"\\nMin-norm token:\", min_id, model.tokenizer.convert_ids_to_tokens([min_id])[0], mn)\nprint(\"Max-norm token:\", max_id, model.tokenizer.convert_ids_to_tokens([max_id])[0], mx)\n\n# Plot: histogram is most readable for ~30k tokens\nplt.figure(figsize=(7, 4))\nplt.hist(col_norms_np, bins=200)\nplt.title(\"BERT unembedding column norms (||W_U[:, token]||)\")\nplt.xlabel(\"L2 norm\")\nplt.ylabel(\"Count\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n# norms\nnorms = col_norms.cpu().numpy()\ntoken_ids = np.arange(len(norms))\n\n# sort by norm\norder = np.argsort(norms)\nsorted_norms = norms[order]\nsorted_ids = token_ids[order]\n\neps = 5*(1e-5)\n\nclusters = []\ncurrent_cluster = [0]\n\nfor i in range(1, len(sorted_norms)):\n    if abs(sorted_norms[i] - sorted_norms[i-1]) <= eps:\n        current_cluster.append(i)\n    else:\n        clusters.append(current_cluster)\n        current_cluster = [i]\n\nclusters.append(current_cluster)\n\nlarge_clusters = [\n    c for c in clusters if len(c) >= 300\n]\n\nprint(f\"Found {len(large_clusters)} large clusters\\n\")\n\nfor i, c in enumerate(large_clusters):\n    norm_val = sorted_norms[c[0]]\n    print(f\"Cluster {i}: size={len(c)}, norm≈{norm_val:.8f}\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i, c in enumerate(large_clusters):\n    print(f\"\\n=== Cluster {i} ===\")\n    print(f\"size={len(c)}, norm≈{sorted_norms[c[0]]:.8f}\\n\")\n    count=0\n    for idx in c:\n        tid = int(sorted_ids[idx])\n        tok = model.tokenizer.convert_ids_to_tokens(tid)\n        if \"unused\" not in tok:\n            print(f\"{tid:5d}  {tok}\")\n        else:\n            count=count+1\n    print (f\"unused tokens: {count}\" )           \n            ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# W_U: [d_model, d_vocab]  [web:89]\nW_U = model2.W_U.detach()\n\n# Each token corresponds to a column vector W_U[:, token_id]\ncol_norms = torch.linalg.norm(W_U, dim=0)          # [d_vocab]\ncol_norms_np = col_norms.cpu().numpy()\n\n# Summary stats\nmn = float(col_norms.min().item())\nmx = float(col_norms.max().item())\nmean = float(col_norms.mean().item())\nstd = float(col_norms.std(unbiased=False).item())\n\nprint(\"Unembed column-norm stats:\")\nprint(\"min :\", mn)\nprint(\"max :\", mx)\nprint(\"mean:\", mean)\nprint(\"std :\", std)\n\n# (Optional) identify tokens with min/max norms\nmin_id = int(torch.argmin(col_norms).item())\nmax_id = int(torch.argmax(col_norms).item())\nprint(\"\\nMin-norm token:\", min_id, model2.tokenizer.convert_ids_to_tokens([min_id])[0], mn)\nprint(\"Max-norm token:\", max_id, model2.tokenizer.convert_ids_to_tokens([max_id])[0], mx)\n\n# Plot: histogram is most readable for ~30k tokens\nplt.figure(figsize=(7, 4))\nplt.hist(col_norms_np, bins=200)\nplt.title(\"BERT unembedding column norms (||W_U[:, token]||)\")\nplt.xlabel(\"L2 norm\")\nplt.ylabel(\"Count\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\n# W_U: [d_model, d_vocab] so token vectors are columns [web:89]\nW_U = model.W_U.detach()  # keep on GPU/CPU, no need to move unless printing a lot\n\ncol_norms = torch.linalg.norm(W_U, dim=0)  # [d_vocab]\n\n# Sort tokens by norm\nsorted_norms, sorted_ids = torch.sort(col_norms, descending=True)\n\ntop_k = 50\nbot_k = 50\n\ntop_ids = sorted_ids[:top_k].tolist()\nbot_ids = sorted_ids[-bot_k:].tolist()\n\ntop_toks = model.tokenizer.convert_ids_to_tokens(top_ids)  # id -> token strings [web:163]\nbot_toks = model.tokenizer.convert_ids_to_tokens(bot_ids)  # id -> token strings [web:163]\n\nprint(f\"Top {top_k} tokens by ||W_U[:,tok]||:\")\nfor i, (tok, tid) in enumerate(zip(top_toks, top_ids)):\n    print(f\"{i+1:>2}. {tok:<15}  id={tid:<6}  norm={sorted_norms[i].item():.6f}\")\n\nprint(f\"\\nBottom {bot_k} tokens by ||W_U[:,tok]||:\")\n# bottom norms are at the end of sorted_norms\nfor j, (tok, tid) in enumerate(zip(bot_toks, bot_ids)):\n    norm_val = col_norms[tid].item()\n    print(f\"{j+1:>2}. {tok:<15}  id={tid:<6}  norm={norm_val:.6f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\n# W_U: [d_model, d_vocab], token vectors are columns [web:89]\nW_U = model.W_U.detach()\n\nhe_id  = model.tokenizer.convert_tokens_to_ids(\"he\")   # token -> id [web:163]\nshe_id = model.tokenizer.convert_tokens_to_ids(\"she\")  # token -> id [web:163]\n\nhe_norm  = torch.linalg.norm(W_U[:, he_id]).item()\nshe_norm = torch.linalg.norm(W_U[:, she_id]).item()\n\nprint(f\"||W_U[:, 'he']||  = {he_norm:.6f}  (id={he_id})\")\nprint(f\"||W_U[:, 'she']|| = {she_norm:.6f} (id={she_id})\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport pandas as pd\n\n# Unembed matrix\nW_U = model.W_U.detach()\ntok = model.tokenizer\n\ndef is_single_wordpiece(s: str) -> bool:\n    pieces = tok.tokenize(s)\n    return (len(pieces) == 1) and (pieces[0] == s)\n\ndef unembed_col_norm(token_str: str) -> float:\n    token_id = tok.convert_tokens_to_ids(token_str)\n    if token_id is None or token_id == tok.unk_token_id:\n        return float(\"nan\")\n    return torch.linalg.norm(W_U[:, token_id]).item()\n\n\n#used gemini 3 to generate pairs\npairs = [\n    (\"he\",\"she\"), (\"him\",\"her\"), (\"his\",\"hers\"), (\"himself\",\"herself\"),\n    (\"mr\",\"mrs\"), (\"sir\",\"madam\"),\n\n    (\"man\",\"woman\"), (\"men\",\"women\"), (\"boy\",\"girl\"), (\"boys\",\"girls\"),\n    (\"father\",\"mother\"), (\"dad\",\"mom\"), (\"daddy\",\"mommy\"),\n    (\"son\",\"daughter\"), (\"sons\",\"daughters\"),\n    (\"brother\",\"sister\"), (\"brothers\",\"sisters\"),\n    (\"uncle\",\"aunt\"), (\"uncles\",\"aunts\"),\n    (\"husband\",\"wife\"), (\"husbands\",\"wives\"),\n    (\"boyfriend\",\"girlfriend\"), (\"boyfriends\",\"girlfriends\"),\n\n    (\"king\",\"queen\"), (\"kings\",\"queens\"),\n    (\"prince\",\"princess\"), (\"princes\",\"princesses\"),\n    (\"gentleman\",\"lady\"), (\"gentlemen\",\"ladies\"),\n\n    (\"grandfather\",\"grandmother\"), (\"grandpa\",\"grandma\"),\n    (\"stepfather\",\"stepmother\"), (\"stepson\",\"stepdaughter\"),\n\n    (\"policeman\",\"policewoman\"),\n    (\"fireman\",\"firewoman\"),\n    (\"chairman\",\"chairwoman\"),\n    (\"businessman\",\"businesswoman\"),\n    (\"waiter\",\"waitress\"),\n    (\"actor\",\"actress\"),\n    (\"hero\",\"heroine\"),\n    (\"monk\",\"nun\"),\n    (\"groom\",\"bride\"),\n\n    (\"john\",\"mary\"), (\"james\",\"jennifer\"), (\"robert\",\"linda\"),\n    (\"michael\",\"elizabeth\"), (\"william\",\"barbara\"),\n    (\"david\",\"susan\"), (\"richard\",\"jessica\"),\n    (\"joseph\",\"sarah\"), (\"thomas\",\"karen\"),\n    (\"charles\",\"nancy\"), (\"daniel\",\"lisa\"),\n    (\"matthew\",\"betty\"), (\"anthony\",\"margaret\"),\n    (\"mark\",\"sandra\"), (\"paul\",\"ashley\"),\n    (\"steven\",\"kimberly\"), (\"andrew\",\"emily\"),\n    (\"kenneth\",\"donna\"), (\"george\",\"michelle\"),\n]\n\nrows = []\nkept_pairs = []\n\nfor m, f in pairs:\n    if is_single_wordpiece(m) and is_single_wordpiece(f):\n        m_id = tok.convert_tokens_to_ids(m)\n        f_id = tok.convert_tokens_to_ids(f)\n\n        if m_id != tok.unk_token_id and f_id != tok.unk_token_id:\n            m_norm = unembed_col_norm(m)\n            f_norm = unembed_col_norm(f)\n\n            rows.append({\n                \"male_token\": m,\n                \"male_id\": m_id,\n                \"male_norm\": m_norm,\n                \"female_token\": f,\n                \"female_id\": f_id,\n                \"female_norm\": f_norm,\n                \"norm_diff_m_minus_f\": m_norm - f_norm\n            })\n            kept_pairs.append((m, f))\n\ndf = pd.DataFrame(rows)\n\nprint(f\"Kept paired tokens: {len(kept_pairs)}\")\nassert len(kept_pairs) >= 50, \"Need at least 50 valid male↔female pairs.\"\n\n\ndf_sorted = df.sort_values(\n    \"norm_diff_m_minus_f\",\n    key=lambda x: x,\n    ascending=False\n)\n\nprint(\"\\n=== Paired unembed column norms (sorted by |male − female|) ===\\n\")\nfor _, r in df_sorted.iterrows():\n    print(\n        f\"{r['male_token']:<14} ({r['male_norm']:.6f})   \"\n        f\"{r['female_token']:<14} ({r['female_norm']:.6f})   \"\n        f\"Δ={r['norm_diff_m_minus_f']:+.6f}\"\n    )\n\n\nstats = pd.DataFrame({\n    \"male\": df[\"male_norm\"].describe(),\n    \"female\": df[\"female_norm\"].describe(),\n    \"male_minus_female\": df[\"norm_diff_m_minus_f\"].describe()\n})\n\nprint(\"\\n=== Summary statistics ===\")\nprint(stats)\n\n\ndf.to_csv(\"gender_token_unembed_norms_paired.csv\", index=False)\nprint(\"\\nWrote gender_token_unembed_norms_paired.csv\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# expt seeing if cosine similarity of the embeddings show gender bias. ","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\n\nstereo = \"The girl is an engineer.\"\nanti   = \"The boy is an engineer.\"\n\ntokens, ttypes, amask = model.to_tokens([stereo, anti])\nlogits, cache = model.run_with_cache(\n    tokens,\n    token_type_ids=ttypes,\n    one_zero_attention_mask=amask,\n    return_type=\"logits\",\n)\n\ndef find_tok_pos(model, tokens_1seq, tok_str):\n    tok_id = model.tokenizer.convert_tokens_to_ids(tok_str)\n    # tokens_1seq: [pos]\n    matches = (tokens_1seq == tok_id).nonzero(as_tuple=False).flatten()\n    assert len(matches) > 0, (tok_str, \"not found\")\n    return int(matches[0])\n\n\ngirl_pos = find_tok_pos(model, tokens[0], \"girl\")\nboy_pos  = find_tok_pos(model, tokens[1], \"boy\")\neng_pos0 = find_tok_pos(model, tokens[0], \"engineer\")\neng_pos1 = find_tok_pos(model, tokens[1], \"engineer\")\n\nlayer_keys = [\"embed.hook_embed\"] + [f\"blocks.{l}.hook_resid_post\" for l in range(model.cfg.n_layers)]+[\"mlm_head.ln.hook_normalized\"]\n\ncos_by_layer = []\nfor k in layer_keys:\n    h = cache[k]  # [batch, pos, d_model]\n    girl_vec = h[0, girl_pos]\n    eng_vec0 = h[0, eng_pos0]\n    boy_vec  = h[1, boy_pos]\n    eng_vec1 = h[1, eng_pos1]\n\n    cos_girl_eng = F.cosine_similarity(girl_vec, eng_vec0, dim=0).item()\n    cos_boy_eng  = F.cosine_similarity(boy_vec,  eng_vec1, dim=0).item()\n    print((k, cos_girl_eng, cos_boy_eng, cos_girl_eng - cos_boy_eng))\n    cos_by_layer.append((k, cos_girl_eng, cos_boy_eng, cos_girl_eng - cos_boy_eng))\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\n\nstereo = \"He is an engineer.\"\nanti   = \"She is an engineer.\"\n\ntokens, ttypes, amask = model.to_tokens([stereo, anti])\nlogits, cache = model.run_with_cache(\n    tokens,\n    token_type_ids=ttypes,\n    one_zero_attention_mask=amask,\n    return_type=\"logits\",\n)\n\n\ngirl_pos = find_tok_pos(model, tokens[0], \"he\")\nboy_pos  = find_tok_pos(model, tokens[1], \"she\")\neng_pos0 = find_tok_pos(model, tokens[0], \"engineer\")\neng_pos1 = find_tok_pos(model, tokens[1], \"engineer\")\n\n\nlayer_keys = [\"embed.hook_embed\"] + [f\"blocks.{l}.hook_resid_post\" for l in range(model.cfg.n_layers)]+[\"mlm_head.ln.hook_normalized\"]\n\ncos_by_layer = []\nfor k in layer_keys:\n    h = cache[k]  # [batch, pos, d_model]\n    girl_vec = h[0, girl_pos]\n    eng_vec0 = h[0, eng_pos0]\n    boy_vec  = h[1, boy_pos]\n    eng_vec1 = h[1, eng_pos1]\n\n    cos_girl_eng = F.cosine_similarity(girl_vec, eng_vec0, dim=0).item()\n    cos_boy_eng  = F.cosine_similarity(boy_vec,  eng_vec1, dim=0).item()\n    print((k, cos_girl_eng, cos_boy_eng, cos_girl_eng - cos_boy_eng))\n    cos_by_layer.append((k, cos_girl_eng, cos_boy_eng, cos_girl_eng - cos_boy_eng))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# experiment 4 - gender bias on wino bias dataset measured by cosine similarity between embeddings","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom datasets import load_dataset\nfrom scipy.stats import ttest_rel\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T16:56:54.582138Z","iopub.execute_input":"2026-01-01T16:56:54.582529Z","iopub.status.idle":"2026-01-01T16:56:54.587027Z","shell.execute_reply.started":"2026-01-01T16:56:54.582496Z","shell.execute_reply":"2026-01-01T16:56:54.586418Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"type1_pro  = load_dataset(\"uclanlp/wino_bias\", \"type1_pro\",  split=\"test\")\ntype1_anti = load_dataset(\"uclanlp/wino_bias\", \"type1_anti\", split=\"test\")\n\ntype2_pro  = load_dataset(\"uclanlp/wino_bias\", \"type2_pro\",  split=\"test\")\ntype2_anti = load_dataset(\"uclanlp/wino_bias\", \"type2_anti\", split=\"test\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T16:56:56.536261Z","iopub.execute_input":"2026-01-01T16:56:56.536808Z","iopub.status.idle":"2026-01-01T16:57:02.162041Z","shell.execute_reply.started":"2026-01-01T16:56:56.536779Z","shell.execute_reply":"2026-01-01T16:57:02.161519Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"assert len(type1_pro) == len(type1_anti)\nassert len(type2_pro) == len(type2_anti)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T17:01:03.348927Z","iopub.execute_input":"2026-01-01T17:01:03.349609Z","iopub.status.idle":"2026-01-01T17:01:03.353242Z","shell.execute_reply.started":"2026-01-01T17:01:03.349563Z","shell.execute_reply":"2026-01-01T17:01:03.352497Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"IGNORE_TOKENS = {\"the\", \"a\", \"an\"}\nPRONOUNS = {\"he\", \"she\", \"him\", \"her\", \"his\", \"hers\"}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T17:01:05.548595Z","iopub.execute_input":"2026-01-01T17:01:05.548892Z","iopub.status.idle":"2026-01-01T17:01:05.553040Z","shell.execute_reply.started":"2026-01-01T17:01:05.548866Z","shell.execute_reply":"2026-01-01T17:01:05.552228Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\n# import pandas as pd\n# from datasets import load_dataset\n\nIGNORE_TOKENS = {\"the\", \"a\", \"an\"}\nPRONOUNS = {\"he\", \"she\", \"him\", \"her\", \"his\", \"hers\"}\nDETERMINERS = IGNORE_TOKENS\n\n\ndef parse_coref_indices(ex):\n    \"\"\"\n    Winobias coreference_clusters is a string list, e.g. ['3','4','6','6'].\n    Treat it as a *single* cluster of indices, remove duplicates, sort.\n    \"\"\"\n    raw = ex[\"coreference_clusters\"]\n    # raw is something like ['3','4','6','6']\n    idxs = sorted({int(i) for i in raw})\n    return idxs\n\ndef build_filtered_examples(dataset, split_name, model, max_examples=None):\n    \"\"\"\n    For one of: type1_pro, type1_anti, type2_pro, type2_anti.\n\n    Returns list of dicts with:\n      - split: split_name\n      - sentence\n      - pron_word, pron_pos\n      - occ_word, occ_pos\n      - coref_indices (string)\n    Constraints:\n      - cluster has exactly 1 pronoun and 1 non-determiner entity\n      - occupation is single BERT token (WordPiece)\n    \"\"\"\n    rows = []\n    n_total, n_bad_coref, n_multi_entities, n_bad_tokenization = 0, 0, 0, 0\n\n    for i, ex in enumerate(dataset):\n        if max_examples is not None and i >= max_examples:\n            break\n\n        n_total += 1\n        words = ex[\"tokens\"]\n        words_l = [w.lower() for w in words]\n\n        try:\n            idxs = parse_coref_indices(ex)\n        except Exception:\n            n_bad_coref += 1\n            continue\n\n        pron_positions = []\n        entity_positions = []\n\n        for idx in idxs:\n            if idx < 0 or idx >= len(words_l):\n                continue\n            w = words_l[idx]\n            if w in PRONOUNS:\n                pron_positions.append(idx)\n            elif w in DETERMINERS:\n                continue\n            else:\n                entity_positions.append(idx)\n\n        if len(pron_positions) != 1 or len(entity_positions) != 1:\n            n_multi_entities += 1\n            continue\n\n        pron_pos = pron_positions[0]\n        occ_pos  = entity_positions[0]\n        pron_word = words[pron_pos]\n        occ_word  = words[occ_pos]\n\n        # BERT tokenization: occupation must be a single token\n        occ_pieces = model.tokenizer.tokenize(occ_word)\n        if len(occ_pieces) != 1:\n            n_bad_tokenization += 1\n            continue\n\n        sentence = \" \".join(words)\n\n        rows.append(\n            {\n                \"split\": split_name,\n                \"sentence\": sentence,\n                \"pron_word\": pron_word,\n                \"pron_pos\": pron_pos,\n                \"occ_word\": occ_word,\n                \"occ_pos\": occ_pos,\n                \"coref_indices\": \";\".join(map(str, idxs)),\n            }\n        )\n\n    print(\n        f\"[{split_name}] total={n_total}, bad_coref={n_bad_coref}, \"\n        f\"multi/none={n_multi_entities}, bad_tok={n_bad_tokenization}, kept={len(rows)}\"\n    )\n    return rows\n\n\n# Build filtered rows for all four subsets\nrows_type1_pro  = build_filtered_examples(type1_pro,  \"type1_pro\",  model)\nrows_type1_anti = build_filtered_examples(type1_anti, \"type1_anti\", model)\nrows_type2_pro  = build_filtered_examples(type2_pro,  \"type2_pro\",  model)\nrows_type2_anti = build_filtered_examples(type2_anti, \"type2_anti\", model)\n\ndf_type1_pro  = pd.DataFrame(rows_type1_pro)\ndf_type1_anti = pd.DataFrame(rows_type1_anti)\ndf_type2_pro  = pd.DataFrame(rows_type2_pro)\ndf_type2_anti = pd.DataFrame(rows_type2_anti)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T17:01:28.483884Z","iopub.execute_input":"2026-01-01T17:01:28.484199Z","iopub.status.idle":"2026-01-01T17:01:28.918859Z","shell.execute_reply.started":"2026-01-01T17:01:28.484172Z","shell.execute_reply":"2026-01-01T17:01:28.918217Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":" # Align pro/anti by index within each type, and concatenate into a single paired df\ndef make_paired_df(df_pro, df_anti, type_name: str):\n    n = min(len(df_pro), len(df_anti))\n    df_pro  = df_pro.iloc[:n].reset_index(drop=True)\n    df_anti = df_anti.iloc[:n].reset_index(drop=True)\n    df_pro  = df_pro.rename(columns=lambda c: c + \"_pro\")\n    df_anti = df_anti.rename(columns=lambda c: c + \"_anti\")\n    paired = pd.concat([df_pro, df_anti], axis=1)\n    paired[\"type\"] = type_name\n    return paired\n\npaired_type1 = make_paired_df(df_type1_pro, df_type1_anti, \"type1\")\npaired_type2 = make_paired_df(df_type2_pro, df_type2_anti, \"type2\")\n\npaired_df = pd.concat([paired_type1, paired_type2], ignore_index=True)\npaired_df.to_csv(\"winobias_filtered_paired_for_bert.csv\", index=False)\nprint(\"Saved winobias_filtered_paired_for_bert.csv with\", len(paired_df), \"pairs\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T17:01:36.784198Z","iopub.execute_input":"2026-01-01T17:01:36.784634Z","iopub.status.idle":"2026-01-01T17:01:36.812351Z","shell.execute_reply.started":"2026-01-01T17:01:36.784598Z","shell.execute_reply":"2026-01-01T17:01:36.811699Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"layer_keys = [\"embed.hook_embed\"] + [f\"blocks.{l}.hook_resid_post\" for l in range(model.cfg.n_layers)]+ [f\"blocks.{l}.hook_normalized_resid_post\" for l in range(model.cfg.n_layers)] + [\"mlm_head.ln.hook_normalized\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T17:04:44.793562Z","iopub.execute_input":"2026-01-01T17:04:44.793839Z","iopub.status.idle":"2026-01-01T17:04:44.798039Z","shell.execute_reply.started":"2026-01-01T17:04:44.793816Z","shell.execute_reply":"2026-01-01T17:04:44.797361Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def batched_layerwise_cos_paired(paired_df, batch_size: int = 32):\n    \"\"\"\n    For each layer k, returns two lists of length N_pairs:\n      cos_pro[k], cos_anti[k]\n    where cos = cos(h_l(pron), h_l(occ)).\n    \"\"\"\n    N = len(paired_df)\n    cos_pro  = {k: [] for k in layer_keys}\n    cos_anti = {k: [] for k in layer_keys}\n\n    for start in range(0, N, batch_size):\n        batch = paired_df.iloc[start : start + batch_size]\n\n        # PRO batch\n        sent_pro  = batch[\"sentence_pro\"].tolist()\n        pron_pro  = batch[\"pron_pos_pro\"].astype(int).tolist()\n        occ_pro   = batch[\"occ_pos_pro\"].astype(int).tolist()\n\n        tok_pro, tt_pro, am_pro = model.to_tokens(sent_pro)\n        tok_pro = tok_pro.to(device)\n        if tt_pro is not None: tt_pro = tt_pro.to(device)\n        if am_pro is not None: am_pro = am_pro.to(device)\n\n        _, cache_pro = model.run_with_cache(\n            tok_pro,\n            token_type_ids=tt_pro,\n            one_zero_attention_mask=am_pro,\n            return_type=\"logits\",\n        )\n\n        B_pro = tok_pro.size(0)\n        idx_b_pro = torch.arange(B_pro, device=device)\n        pron_idx_pro = torch.tensor(pron_pro, device=device)\n        occ_idx_pro  = torch.tensor(occ_pro,  device=device)\n\n        # ANTI batch\n        sent_anti = batch[\"sentence_anti\"].tolist()\n        pron_anti = batch[\"pron_pos_anti\"].astype(int).tolist()\n        occ_anti  = batch[\"occ_pos_anti\"].astype(int).tolist()\n\n        tok_anti, tt_anti, am_anti = model.to_tokens(sent_anti)\n        tok_anti = tok_anti.to(device)\n        if tt_anti is not None: tt_anti = tt_anti.to(device)\n        if am_anti is not None: am_anti = am_anti.to(device)\n\n        _, cache_anti = model.run_with_cache(\n            tok_anti,\n            token_type_ids=tt_anti,\n            one_zero_attention_mask=am_anti,\n            return_type=\"logits\",\n        )\n\n        B_anti = tok_anti.size(0)\n        assert B_pro == B_anti\n        idx_b_anti = torch.arange(B_anti, device=device)\n        pron_idx_anti = torch.tensor(pron_anti, device=device)\n        occ_idx_anti  = torch.tensor(occ_anti,  device=device)\n\n        for k in layer_keys:\n            h_pro   = cache_pro[k]   # [B, pos, d_model]\n            h_anti  = cache_anti[k]  # [B, pos, d_model]\n\n            pron_vecs_pro = h_pro[idx_b_pro,  pron_idx_pro]\n            occ_vecs_pro  = h_pro[idx_b_pro,  occ_idx_pro]\n            cos_batch_pro = F.cosine_similarity(pron_vecs_pro, occ_vecs_pro, dim=-1)\n\n            pron_vecs_anti = h_anti[idx_b_anti, pron_idx_anti]\n            occ_vecs_anti  = h_anti[idx_b_anti, occ_idx_anti]\n            cos_batch_anti = F.cosine_similarity(pron_vecs_anti, occ_vecs_anti, dim=-1)\n\n            cos_pro[k].extend(cos_batch_pro.detach().cpu().tolist())\n            cos_anti[k].extend(cos_batch_anti.detach().cpu().tolist())\n\n        print(f\"Processed {start + B_pro} / {N} pairs\")\n\n    return cos_pro, cos_anti","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T17:02:16.233556Z","iopub.execute_input":"2026-01-01T17:02:16.234160Z","iopub.status.idle":"2026-01-01T17:02:16.243722Z","shell.execute_reply.started":"2026-01-01T17:02:16.234129Z","shell.execute_reply":"2026-01-01T17:02:16.243002Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cos_pro, cos_anti = batched_layerwise_cos_paired(paired_df, batch_size=64)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T17:04:47.513680Z","iopub.execute_input":"2026-01-01T17:04:47.514302Z","iopub.status.idle":"2026-01-01T17:04:51.829988Z","shell.execute_reply.started":"2026-01-01T17:04:47.514270Z","shell.execute_reply":"2026-01-01T17:04:51.829025Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print (cos_pro,cos_anti)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#helper function for better prints\nimport re\ndef clean_layer_name(name: str) -> str:\n    name = str(name)\n    if \"embed\" in name:\n        return \"Emb\"\n    if \"mlm_head\" in name:\n        return \"Head_norm\" if \"norm\" in name or \"normalized\" in name else \"Head\"\n    name = name.replace(\"blocks.\", \"\")\n    m = re.search(r\"(\\d+)\", name)\n    if not m:\n        base = name\n    else:\n        layer_idx = m.group(1)\n        base = f\"L{layer_idx}\"\n    if \"norm\" in name or \"normalized\" in name:\n        base = base + \"_norm\"\n    return base\n\nres_df[\"layer\"] = res_df[\"layer\"].astype(str).apply(clean_layer_name)\nprint(res_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T17:34:49.023598Z","iopub.execute_input":"2026-01-01T17:34:49.023919Z","iopub.status.idle":"2026-01-01T17:34:49.035226Z","shell.execute_reply.started":"2026-01-01T17:34:49.023891Z","shell.execute_reply":"2026-01-01T17:34:49.034586Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#pttest\nresults = []\nfrom scipy.stats import ttest_rel\n\nfor layer_name in layer_keys:\n    x = np.array(cos_pro[layer_name], dtype=np.float32)   # pro\n    y = np.array(cos_anti[layer_name], dtype=np.float32)  # anti\n    assert x.shape == y.shape\n\n    delta = y - x  # anti - pro; <0 means pro (stereotype) higher similarity\n    mean_delta = float(delta.mean())\n\n    delta2 = (y - x)*2/(y+x)  # anti - pro; <0 means pro (stereotype) higher similarity\n\n    mean_delta2 = float(delta2.mean())\n    n = int(delta.size)\n\n    t_stat, p_t = ttest_rel(y, x)        # tests mean(delta) == 0\n\n    results.append(\n        {\n            \"layer\": layer_name,\n            \"mean_delta\": mean_delta,\n            \"mean_delta2\": mean_delta2,\n            \"p_ttest\": float(p_t),\n            \"n_pairs\": n,\n        }\n    )\n\nres_df = pd.DataFrame(results)\nres_df.to_csv(\"winobias_layerwise_paired_tests.csv\", index=False)\nres_df[\"layer\"] = res_df[\"layer\"].astype(str).apply(clean_layer_name)\nprint(res_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T17:39:10.203452Z","iopub.execute_input":"2026-01-01T17:39:10.204049Z","iopub.status.idle":"2026-01-01T17:39:10.255248Z","shell.execute_reply.started":"2026-01-01T17:39:10.204015Z","shell.execute_reply":"2026-01-01T17:39:10.254700Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\ndef permutation_pvalue_xy(x, y, n_permutations=10000, seed=42):\n    \"\"\"\n    Two-sided permutation test for mean(y - x) == 0,\n    implemented by shuffling the pooled (x,y) values and\n    randomly re-partitioning into two groups of size len(x), len(y)\n    each permutation.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n\n    x = np.asarray(x, dtype=np.float64)\n    y = np.asarray(y, dtype=np.float64)\n\n    x = x[~np.isnan(x)]\n    y = y[~np.isnan(y)]\n\n    n_x, n_y = len(x), len(y)\n    if n_x < 2 or n_y < 2:\n        return np.nan, np.nan\n\n    obs_stat = y.mean() - x.mean()\n\n    pooled = np.concatenate([x, y])\n    n_total = pooled.size\n\n    perm_stats = np.empty(n_permutations, dtype=np.float64)\n    for i in range(n_permutations):\n        rng.shuffle(pooled)\n        x_perm = pooled[:n_x]\n        y_perm = pooled[n_x:]\n        perm_stats[i] = y_perm.mean() - x_perm.mean()\n\n    p_val = np.mean(np.abs(perm_stats) >= np.abs(obs_stat))\n    return float(obs_stat), float(p_val)\n\nresults = []\n\nfor layer_name in layer_keys:\n    x = np.array(cos_pro[layer_name], dtype=np.float32)   \n    y = np.array(cos_anti[layer_name], dtype=np.float32)\n    assert x.shape == y.shape\n\n    delta  = y - x\n    delta2 = (y - x) * 2 / (y + x)\n\n    n = int(delta.size)\n\n    mean_delta_obs,  p_perm_delta  = permutation_pvalue_xy(x, y, n_permutations=10000)\n\n    x2 = -delta2 / 2.0\n    y2 = +delta2 / 2.0\n    mean_delta2_obs, p_perm_delta2 = permutation_pvalue_xy(x2, y2, n_permutations=10000)\n\n    results.append(\n        {\n            \"layer\": layer_name,\n            \"mean_delta\":   float(delta.mean()),\n            \"p_perm_delta\": float(p_perm_delta),\n            \"mean_delta2\":  float(delta2.mean()),\n            \"p_perm_delta2\": float(p_perm_delta2),\n            \"n_pairs\": n,\n        }\n    )\n\nres_df = pd.DataFrame(results)\nres_df.to_csv(\"winobias_layerwise_permutation_tests_xy.csv\", index=False)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#explains the crazy bias in delta2\nlayer = \"L21_norm\"  # the one with -6.73\n\nx = np.array(cos_pro[ \"blocks.21.hook_normalized_resid_post\"])\ny = np.array(cos_anti[\"blocks.21.hook_normalized_resid_post\"])\n\ndelta2 = (y - x) * 2 /(np.abs(y + x))\ndelta= y-x\n\nprint(delta2.min(), delta2.max())\nprint(np.quantile(delta2[~np.isnan(delta2)], [0.0, 0.01, 0.5, 0.99, 1.0]))\nprint(delta.min(), delta.max())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T18:29:43.407785Z","iopub.execute_input":"2026-01-01T18:29:43.409050Z","iopub.status.idle":"2026-01-01T18:29:43.415986Z","shell.execute_reply.started":"2026-01-01T18:29:43.409010Z","shell.execute_reply":"2026-01-01T18:29:43.415217Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# expt for studying gender bias in hidden states in bert large using logits/ probability","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn.functional as F\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom datasets import load_dataset\nfrom scipy.stats import ttest_1samp, wilcoxon\n\nfrom transformer_lens import HookedEncoder","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"he_id  = model.tokenizer.convert_tokens_to_ids(\"he\")\nshe_id = model.tokenizer.convert_tokens_to_ids(\"she\")\nmask_id = model.tokenizer.mask_token_id\n\nlayer_keys = (\n    [\"embed.hook_embed\"]\n    + [f\"blocks.{l}.hook_resid_post\" for l in range(model.cfg.n_layers)]\n    + [f\"blocks.{l}.hook_normalized_resid_post\" for l in range(model.cfg.n_layers)]\n    + [\"mlm_head.ln.hook_normalized\"]\n)\n\nprint(f\"he_id={he_id}, she_id={she_id}, mask_id={mask_id}\")\nprint(f\"Layer keys: {len(layer_keys)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"IGNORE_TOKENS = {\"the\", \"a\", \"an\"}\nPRONOUNS = {\"he\", \"she\", \"him\", \"her\", \"his\", \"hers\"}\n\ndef parse_coref_indices(ex):\n    \"\"\"Parse Winobias coreference_clusters string list to int indices.\"\"\"\n    raw = ex[\"coreference_clusters\"]\n    return sorted({int(i) for i in raw})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess_winobias(dataset, split_name):\n    \"\"\"\n    Returns DataFrame with:\n    - sentence_original\n    - sentence_masked (with pronoun replaced by [MASK])\n    - pron_pos (original token position of pronoun)\n    - pron_word (original pronoun)\n    - occ_word (profession word)\n    - split\n    \"\"\"\n    rows = []\n    n_total, n_bad_coref, n_no_pronoun, n_bad_bert_tok = 0, 0, 0, 0\n\n    for ex in dataset:\n        n_total += 1\n        words = ex[\"tokens\"]\n        words_l = [w.lower() for w in words]\n\n        try:\n            idxs = parse_coref_indices(ex)\n        except Exception:\n            n_bad_coref += 1\n            continue\n\n        # Find pronoun and non-determiner entity in cluster\n        pron_pos, entity_pos = None, None\n        for idx in idxs:\n            if idx < 0 or idx >= len(words_l):\n                continue\n            w = words_l[idx]\n            if w in PRONOUNS:\n                if pron_pos is None:  # Take first pronoun\n                    pron_pos = idx\n            elif w not in IGNORE_TOKENS:\n                if entity_pos is None:  # Take first non-determiner entity\n                    entity_pos = idx\n\n        if pron_pos is None or entity_pos is None:\n            n_no_pronoun += 1\n            continue\n\n        pron_word = words[pron_pos]\n        occ_word = words[entity_pos]\n\n        # BERT tokenization: occupation must be single token\n        occ_pieces = model.tokenizer.tokenize(occ_word)\n        if len(occ_pieces) != 1:\n            n_bad_bert_tok += 1\n            continue\n\n        # Create masked sentence: replace pronoun with [MASK]\n        masked_words = words.copy()\n        masked_words[pron_pos] = model.tokenizer.mask_token\n        sentence_masked = \" \".join(masked_words)\n        sentence_orig = \" \".join(words)\n\n        rows.append({\n            \"split\": split_name,\n            \"sentence_orig\": sentence_orig,\n            \"sentence_masked\": sentence_masked,\n            \"pron_pos\": pron_pos,\n            \"pron_word\": pron_word,\n            \"occ_word\": occ_word,\n            \"occ_pos\": entity_pos,\n        })\n\n    print(f\"[{split_name}] total={n_total}, bad_coref={n_bad_coref}, \"\n          f\"no_pronoun={n_no_pronoun}, bad_tok={n_bad_bert_tok}, kept={len(rows)}\")\n    return pd.DataFrame(rows)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load and process all Winobias splits\nprint(\"Loading Winobias...\")\ntype1_pro  = load_dataset(\"uclanlp/wino_bias\", \"type1_pro\",  split=\"test\")\ntype2_pro  = load_dataset(\"uclanlp/wino_bias\", \"type2_pro\",  split=\"test\")\ndf_type1_pro  = preprocess_winobias(type1_pro,  \"type1_pro\")\ndf_type2_pro  = preprocess_winobias(type2_pro,  \"type2_pro\")\n\nwinobias_df = pd.concat([\n    df_type1_pro, \n    df_type2_pro\n], ignore_index=True)\n\nwinobias_df.to_csv(\"winobias_masked_pronoun.csv\", index=False)\nprint(f\"Saved {len(winobias_df)} masked sentences\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define gender pairs for Winobias pronouns\nMALE_PRONOUNS   = {\"he\", \"him\", \"his\"}\nFEMALE_PRONOUNS = {\"she\", \"her\", \"hers\"}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn.functional as F","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_pronoun_pair_ids(tokenizer, original_pron):\n    \"\"\"\n    Returns (male_id, female_id) corresponding to the grammatical role\n    of the original pronoun.\n    \"\"\"\n    p = original_pron.lower()\n    \n    if p in [\"he\", \"she\"]:\n        m, f = \"he\", \"she\"\n    elif p in [\"him\", \"her\"]:\n\n        m, f = \"him\", \"her\" \n\n    elif p in [\"his\", \"hers\"]:\n        m, f = \"his\", \"her\" \n    else:\n        # Fallback\n        m, f = \"he\", \"she\"\n    if p == \"his\":\n        m, f = \"his\", \"her\"\n    elif p == \"hers\":\n        m, f = \"his\", \"hers\"\n\n    m_id = tokenizer.convert_tokens_to_ids(m)\n    f_id = tokenizer.convert_tokens_to_ids(f)\n    return m_id, f_id\n\ndef batched_logit_analysis(winobias_df, batch_size=32):\n    \"\"\"\n    For each sentence:\n    - Identify correct male/female pronoun pair ids based on 'pron_word'\n    - Compute logit(male) - logit(female) at mask position\n    \"\"\"\n    N = len(winobias_df)\n    results = []\n\n    for start in range(0, N, batch_size):\n        end = min(start + batch_size, N)\n        batch = winobias_df.iloc[start:end]\n        \n        sentences = batch[\"sentence_masked\"].tolist()\n        pron_words = batch[\"pron_word\"].tolist()\n        occ_words  = batch[\"occ_word\"].tolist()\n        \n        # Tokenize batch\n        tokens, ttypes, amask = model.to_tokens(sentences)\n        tokens = tokens.to(device)\n        if ttypes is not None: ttypes = ttypes.to(device)\n        if amask is not None:  amask = amask.to(device)\n\n        # Forward pass\n        logits, cache = model.run_with_cache(\n            tokens,\n            token_type_ids=ttypes,\n            one_zero_attention_mask=amask,\n            return_type=\"logits\",\n        )\n\n        B = tokens.shape[0]\n        \n        # Prepare per-sample indices\n        mask_positions = []\n        male_ids = []\n        female_ids = []\n        \n        for b in range(B):\n            # Mask pos\n            m_pos = (tokens[b] == mask_id).nonzero(as_tuple=False).item()\n            mask_positions.append(m_pos)\n            \n            # Pronoun pair ids\n            mid, fid = get_pronoun_pair_ids(model.tokenizer, pron_words[b])\n            male_ids.append(mid)\n            female_ids.append(fid)\n\n        # Convert to tensors for gathering\n        batch_idx = torch.arange(B, device=device)\n        mask_pos_t = torch.tensor(mask_positions, device=device)\n        male_ids_t = torch.tensor(male_ids, device=device)\n        female_ids_t = torch.tensor(female_ids, device=device)\n\n        # 1. True final logits\n        # logits: [B, seq, vocab]\n        final_logits_at_mask = logits[batch_idx, mask_pos_t, :] # [B, vocab]\n        \n        true_male_logits   = final_logits_at_mask.gather(1, male_ids_t.unsqueeze(1)).squeeze(1)\n        true_female_logits = final_logits_at_mask.gather(1, female_ids_t.unsqueeze(1)).squeeze(1)\n        true_diff = (true_male_logits - true_female_logits).detach().cpu().numpy()\n\n        true_probs = F.softmax(final_logits_at_mask, dim=-1)\n        true_male_probs   = true_probs.gather(1, male_ids_t.unsqueeze(1)).squeeze(1)\n        true_female_probs = true_probs.gather(1, female_ids_t.unsqueeze(1)).squeeze(1)\n        true_prob_diff = (true_male_probs - true_female_probs).detach().cpu().numpy()\n\n        # 2. Logit lens per layer\n        for k in layer_keys:\n            resid = cache[k] # [B, seq, d_model]\n            resid_at_mask = resid[batch_idx, mask_pos_t, :] # [B, d_model]\n            \n            layer_logits_all = resid_at_mask @ model.W_U + model.b_U # [B, vocab]\n            \n            l_male = layer_logits_all.gather(1, male_ids_t.unsqueeze(1)).squeeze(1)\n            l_female = layer_logits_all.gather(1, female_ids_t.unsqueeze(1)).squeeze(1)\n            layer_diff = (l_male - l_female).detach().cpu().numpy()\n\n            layer_probs = F.softmax(layer_logits_all, dim=-1)\n            p_male = layer_probs.gather(1, male_ids_t.unsqueeze(1)).squeeze(1)\n            p_female = layer_probs.gather(1, female_ids_t.unsqueeze(1)).squeeze(1)\n            layer_prob_diff = (p_male - p_female).detach().cpu().numpy()\n\n            for i in range(B):\n                results.append({\n                    \"split\": batch.iloc[i][\"split\"],\n                    \"occ_word\": occ_words[i],\n                    \"pron_word\": pron_words[i],\n                    \"layer\": k,\n                    \"true_logit_diff\": true_diff[i],\n                    \"layer_logit_diff\": layer_diff[i],\n                    \"logit_male\": l_male[i].item(),\n                    \"logit_female\": l_female[i].item(),\n\n                    \"true_prob_diff\": true_prob_diff[i],\n                    \"layer_prob_diff\": layer_prob_diff[i],\n                    \"prob_male\": p_male[i].item(),\n                    \"prob_female\": p_female[i].item(),\n                })\n\n        print(f\"Processed {end}/{N} sentences\")\n\n    return pd.DataFrame(results)\n\n# Run analysis\nprint(\"Running batched logit lens analysis...\")\nanalysis_df = batched_logit_analysis(winobias_df)\nanalysis_df.to_csv(\"winobias_pronoun_mask_logit_bias.csv\", index=False)\nprint(\"Saved winobias_pronoun_mask_logit_bias.csv\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from scipy.stats import ttest_rel","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#  Occupation-wise stats\ndef occupation_bias_stats(analysis_df, layers_of_interest=None):\n    \"\"\"\n    Groups by occ_word + layer, computes:\n    - mean(logit(male) - logit(female)) per occupation\n    - t-test p-value per occupation\n    paired ttest on male v/s female\n    \"\"\"\n    if layers_of_interest is None:\n        layers_of_interest = layer_keys  # Default: final layer\n        \n    results = []\n    \n    for layer in layers_of_interest:\n        layer_df = analysis_df[analysis_df[\"layer\"] == layer]\n        for occ_word, group in layer_df.groupby(\"occ_word\"):\n            logit_diffs = group[\"layer_logit_diff\"].values\n            prob_diffs  = group[\"layer_prob_diff\"].values\n            male_logits = group[\"logit_male\"].values\n            female_logits = group[\"logit_female\"].values\n            male_probs = group[\"prob_male\"].values\n            female_probs = group[\"prob_female\"].values\n            \n            # Remove NaNs\n            # clean_diffs = diffs[~np.isnan(diffs)]\n            # n_clean = len(clean_diffs)\n            valid_mask = ~(np.isnan(logit_diffs) | np.isnan(male_logits) | np.isnan(female_logits))\n            logit_clean = logit_diffs[valid_mask]\n            male_logit_clean = male_logits[valid_mask]\n            female_logit_clean = female_logits[valid_mask]\n            \n            prob_valid_mask = ~(np.isnan(prob_diffs) | np.isnan(male_probs) | np.isnan(female_probs))\n            prob_clean = prob_diffs[prob_valid_mask]\n            male_prob_clean = male_probs[prob_valid_mask]\n            female_prob_clean = female_probs[prob_valid_mask]\n\n            n_samples = len(logit_clean)\n            if n_samples < 2:\n                continue\n\n            mean_logit_diff = np.mean(logit_clean)\n            mean_prob_diff = np.mean(prob_clean)\n            t_logit_diff, p_logit_diff = ttest_1samp(logit_clean, popmean=0)\n            t_prob_diff, p_prob_diff = ttest_1samp(prob_clean, popmean=0)\n            \n            # NEW: Paired t-tests (male vs female directly)\n            t_logit_paired, p_logit_paired = ttest_rel(male_logit_clean, female_logit_clean)\n            t_prob_paired, p_prob_paired = ttest_rel(male_prob_clean, female_prob_clean)\n            \n            \n            \n            results.append({\n                \"layer\": layer,\n                \"occ_word\": occ_word,\n                \"n_sentences\": n_samples,\n\n                # one sample t-tests\n                \"mean_logit_diff\": mean_logit_diff,\n                \"t_logit_diff\": t_logit_diff,\n                \"p_logit_diff\": p_logit_diff,  # 1samp on differences\n                \"mean_prob_diff\": mean_prob_diff,\n                \"t_prob_diff\": t_prob_diff,\n                \"p_prob_diff\": p_prob_diff,\n\n                # Paired t-tests (NEW)\n                \"mean_logit_male\": np.mean(male_logit_clean),\n                \"mean_logit_female\": np.mean(female_logit_clean),\n                \"t_logit_paired\": t_logit_paired,\n                \"p_logit_paired\": p_logit_paired,  # paired male vs female logits\n                \"mean_prob_male\": np.mean(male_prob_clean),\n                \"mean_prob_female\": np.mean(female_prob_clean),\n                \"t_prob_paired\": t_prob_paired,\n                \"p_prob_paired\": p_prob_paired,   # paired male vs female probs\n\n                \"std_logit_diff\": np.std(logit_clean),\n                \"std_prob_diff\": np.std(prob_clean),\n                \n            })\n    return pd.DataFrame(results)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"occupation bias stats with paired t-tests...\")\nocc_bias_stats = occupation_bias_stats(analysis_df, layer_keys)\nocc_bias_stats.to_csv(\"winobias_occupation_wise_bias_logit_prob_paired.csv\", index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\nprint(\"\\n=== UPDATED OCCUPATION BIAS STATS (1-SAMPLE + PAIRED T-TESTS) ===\")\nprint(occ_bias_stats.round(4))\n\n# Enhanced printing with both test types\nfor layer in layer_keys:\n    layer_data = occ_bias_stats[occ_bias_stats[\"layer\"] == layer]\n    \n    print(f\"\\n===== {layer} =====\")\n    \n    print(\"\\nTop 10 Male-biased (LOGIT DIFF, 1-SAMPLE T-TEST):\")\n    print(layer_data.nlargest(10, \"mean_logit_diff\")[[\"occ_word\", \"mean_logit_diff\", \"p_logit_diff\", \"n_sentences\"]])\n    \n    print(\"\\nTop 10 Male-biased (LOGIT PAIRED T-TEST):\")\n    print(layer_data.nlargest(10, \"mean_logit_male\")[\n        [\"occ_word\", \"mean_logit_male\", \"mean_logit_female\", \"p_logit_paired\", \"n_sentences\"]\n    ])\n    \n    print(\"\\nTop 10 Female-biased (LOGIT DIFF, 1-SAMPLE T-TEST):\")\n    print(layer_data.nsmallest(10, \"mean_logit_diff\")[[\"occ_word\", \"mean_logit_diff\", \"p_logit_diff\", \"n_sentences\"]])\n    \n    print(\"\\nTop 10 Female-biased (LOGIT PAIRED T-TEST):\")\n    print(layer_data.nlargest(10, \"mean_logit_female\")[\n        [\"occ_word\", \"mean_logit_male\", \"mean_logit_female\", \"p_logit_paired\", \"n_sentences\"]\n    ])\n    \n    print(\"\\nTop 10 Male-biased (PROB DIFF, 1-SAMPLE T-TEST):\")\n    print(layer_data.nlargest(10, \"mean_prob_diff\")[[\"occ_word\", \"mean_prob_diff\", \"p_prob_diff\", \"n_sentences\"]])\n    \n    print(\"\\nTop 10 Male-biased (PROB PAIRED T-TEST):\")\n    print(layer_data.nlargest(10, \"mean_prob_male\")[\n        [\"occ_word\", \"mean_prob_male\", \"mean_prob_female\", \"p_prob_paired\", \"n_sentences\"]\n    ])\n\n# Summary statistics comparing both tests\nprint(\"\\n=== TEST COMPARISON SUMMARY ===\")\nsummary = occ_bias_stats.groupby(\"layer\").agg({\n    \"p_logit_diff\": [\"mean\", \"median\"],\n    \"p_logit_paired\": [\"mean\", \"median\"],\n    \"p_prob_diff\": [\"mean\", \"median\"],\n    \"p_prob_paired\": [\"mean\", \"median\"],\n}).round(4)\nprint(summary)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\n\ndef layer_sort_key(layer):\n    if layer.startswith(\"embed\"):\n        return -1\n    m = re.search(r'blocks\\.(\\d+)\\.', layer)\n    if m:\n        return int(m.group(1))\n    return 1e9 \n\n\n\nocc_bias_stats_prob = occ_bias_stats[\n    occ_bias_stats[\"layer\"] != \"mlm_head.ln.hook_normalized\"\n]\n\npivot_prob = occ_bias_stats_prob.pivot(\n    index=\"occ_word\",\n    columns=\"layer\",\n    values=\"mean_prob_diff\"\n).fillna(0)\n\nordered_layers = sorted(pivot_prob.columns, key=layer_sort_key)\npivot_prob = pivot_prob[ordered_layers]\n\nplt.figure(figsize=(14, 10))\nsns.heatmap(pivot_prob, center=0, cmap=\"RdBu_r\", annot=False)\nplt.title(\"Occupation Probability Bias: P(male) − P(female)\")\nplt.ylabel(\"Occupation\")\nplt.xlabel(\"Layer\")\nplt.tight_layout()\nplt.savefig(\"occupation_bias_heatmap_probs.png\", dpi=200)\nplt.show()\n\n# Top occupations by absolute bias (final layer)\nfinal_layer_bias = occ_bias_stats[occ_bias_stats[\"layer\"] == \"mlm_head.ln.hook_normalized\"]\nfinal_layer_bias[\"abs_prob\"] = np.abs(final_layer_bias[\"mean_prob_diff\"])\n\nprint(\"\\n=== STRONGEST BIAS (prob)(final layer) ===\")\nstrongest = final_layer_bias.nlargest(20, \"abs_prob\")[[\"occ_word\", \"mean_prob_diff\", \"p_value_prob\", \"n_sentences\"]]\nprint(strongest.round(4))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\n\ndef layer_sort_key(layer):\n    if layer.startswith(\"embed\"):\n        return -1\n    m = re.search(r'blocks\\.(\\d+)\\.', layer)\n    if m:\n        return int(m.group(1))\n    return 1e9 \n\n\n\nocc_bias_stats_prob = occ_bias_stats[\n    occ_bias_stats[\"layer\"] != \"mlm_head.ln.hook_normalized\"\n]\n\npivot_prob = occ_bias_stats_prob.pivot(\n    index=\"occ_word\",\n    columns=\"layer\",\n    values=\"mean_logit_diff\"\n).fillna(0)\n\nordered_layers = sorted(pivot_prob.columns, key=layer_sort_key)\npivot_prob = pivot_prob[ordered_layers]\n\nplt.figure(figsize=(14, 10))\nsns.heatmap(pivot_prob, center=0, cmap=\"RdBu_r\", annot=False)\nplt.title(\"Occupation Logit Bias: P(male) − P(female)\")\nplt.ylabel(\"Occupation\")\nplt.xlabel(\"Layer\")\nplt.tight_layout()\nplt.savefig(\"occupation_bias_heatmap_logits_w_o_mlm.png\", dpi=200)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\n\ndef layer_sort_key(layer):\n    if layer.startswith(\"embed\"):\n        return -1\n    m = re.search(r'blocks\\.(\\d+)\\.', layer)\n    if m:\n        return int(m.group(1))\n    return 1e9 \n\n\npivot_prob = occ_bias_stats.pivot(\n    index=\"occ_word\",\n    columns=\"layer\",\n    values=\"mean_logit_diff\"\n).fillna(0)\n\nordered_layers = sorted(pivot_prob.columns, key=layer_sort_key)\npivot_prob = pivot_prob[ordered_layers]\n\nplt.figure(figsize=(14, 10))\nsns.heatmap(pivot_prob, center=0, cmap=\"RdBu_r\", annot=False)\nplt.title(\"Occupation Logit Bias: P(male) − P(female)\")\nplt.ylabel(\"Occupation\")\nplt.xlabel(\"Layer\")\nplt.tight_layout()\nplt.savefig(\"occupation_bias_heatmap_probs.png\", dpi=200)\nplt.show()\n\n# Top occupations by absolute bias (final layer)\nfinal_layer_bias = occ_bias_stats[occ_bias_stats[\"layer\"] == \"mlm_head.ln.hook_normalized\"]\nfinal_layer_bias[\"abs_bias\"] = np.abs(final_layer_bias[\"mean_logit_diff\"])\n\nprint(\"\\n=== STRONGEST BIAS (final layer) ===\")\nstrongest = final_layer_bias.nlargest(20, \"abs_bias\")[[\"occ_word\", \"mean_logit_diff\", \"p_value_logit\", \"n_sentences\"]]\nprint(strongest.round(4))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# occupation wise plots","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport regex as re\nimport os\n\nos.makedirs(\"bias_plots\", exist_ok=True)\n\nocc_bias_stats = pd.read_csv(\n    \"winobias_occupation_wise_bias_logit_prob.csv\"\n)\n\nfinal_layer = \"mlm_head.ln.hook_normalized\"\nfinal_occ_bias = occ_bias_stats[\n    occ_bias_stats[\"layer\"] == final_layer\n].copy()\n\nfinal_occ_bias[\"abs_bias\"] = np.abs(final_occ_bias[\"mean_logit_diff\"])\n\nmale_top5 = (\n    final_occ_bias[final_occ_bias[\"mean_logit_diff\"] > 0]\n    .sort_values(\"abs_bias\", ascending=False)\n    .head(5)[\"occ_word\"]\n    .tolist()\n)\n\nfemale_top5 = (\n    final_occ_bias[final_occ_bias[\"mean_logit_diff\"] < 0]\n    .sort_values(\"abs_bias\", ascending=False)\n    .head(5)[\"occ_word\"]\n    .tolist()\n)\n\nprint(\"Top 5 Male:\", male_top5)\nprint(\"Top 5 Female:\", female_top5)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def pval_column(value_col):\n    return \"p_value_logit\" if value_col == \"mean_logit_diff\" else \"p_value_prob\"\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def annotate_pvals(bars, pvals, y_scale):\n    for bar, p in zip(bars, pvals):\n        if np.isnan(p):\n            continue\n\n        h = bar.get_height()\n        offset = 0.03 * y_scale\n\n        plt.text(\n            bar.get_x() + bar.get_width() / 2,\n            h + np.sign(h) * offset,\n            f\"p={p:.3f}\",\n            ha=\"center\",\n            va=\"bottom\" if h >= 0 else \"top\",\n            fontsize=9,\n            rotation=90\n        )\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def layer_index(layer):\n    if \"embed\" in layer:\n        return -1\n    if \"mlm_head\" in layer:\n        return 10_000\n    m = re.search(r\"blocks\\.(\\d+)\\.\", layer)\n    return int(m.group(1)) if m else 9_999\n\n\ndef layer_short(layer):\n    if \"embed\" in layer:\n        return \"Emb\"\n    if \"mlm_head\" in layer:\n        return \"Head\"\n    m = re.search(r\"blocks\\.(\\d+)\\.\", layer)\n    return f\"L{m.group(1)}\" if m else layer\n\n\ndef hook_type(layer):\n    if \"normalized\" in layer:\n        return \"norm\"\n    return \"raw\"\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_single_occupation(\n    occ,\n    bias_type,\n    value_col,\n    pval_col,\n    title_suffix,\n    fname_suffix,\n):\n    occ_data = occ_bias_stats[occ_bias_stats[\"occ_word\"] == occ].copy()\n    if occ_data.empty:\n        return\n\n    # Remove MLM head for probability plots\n    if value_col == \"mean_prob_diff\":\n        occ_data = occ_data[~occ_data[\"layer\"].str.contains(\"mlm_head\")]\n\n    occ_data[\"layer_idx\"] = occ_data[\"layer\"].apply(layer_index)\n    occ_data[\"layer_short\"] = occ_data[\"layer\"].apply(layer_short)\n    occ_data[\"hook\"] = occ_data[\"layer\"].apply(hook_type)\n\n    occ_data = occ_data.sort_values(\"layer_idx\")\n\n    layers = occ_data[\"layer_short\"].unique()\n    x = np.arange(len(layers))\n    width = 0.35\n\n    raw_vals, norm_vals = [], []\n    raw_pvals, norm_pvals = [], []\n\n    for l in layers:\n        raw = occ_data[\n            (occ_data[\"layer_short\"] == l) & (occ_data[\"hook\"] == \"raw\")\n        ]\n        norm = occ_data[\n            (occ_data[\"layer_short\"] == l) & (occ_data[\"hook\"] == \"norm\")\n        ]\n\n        raw_vals.append(raw[value_col].values[0] if len(raw) else 0.0)\n        norm_vals.append(norm[value_col].values[0] if len(norm) else 0.0)\n\n        raw_pvals.append(raw[pval_col].values[0] if len(raw) else np.nan)\n        norm_pvals.append(norm[pval_col].values[0] if len(norm) else np.nan)\n\n    raw_vals = np.array(raw_vals)\n    norm_vals = np.array(norm_vals)\n\n    y_scale = np.max(np.abs(np.concatenate([raw_vals, norm_vals]))) + 1e-6\n\n    plt.figure(figsize=(11, 6))\n\n    bars_raw = plt.bar(\n        x - width / 2,\n        raw_vals,\n        width,\n        label=\"resid_post\",\n        alpha=0.8,\n        edgecolor=\"black\",\n    )\n\n    bars_norm = plt.bar(\n        x + width / 2,\n        norm_vals,\n        width,\n        label=\"resid_post_norm\",\n        alpha=0.8,\n        edgecolor=\"black\",\n    )\n\n    plt.axhline(0, color=\"black\", linewidth=1)\n    plt.xticks(x, layers, rotation=45)\n    plt.ylabel(value_col)\n    plt.xlabel(\"Layer\")\n\n    plt.title(f\"{occ} ({bias_type})\\n{title_suffix}\", fontsize=13)\n    plt.legend()\n\n    annotate_pvals(bars_raw, raw_pvals, y_scale)\n    annotate_pvals(bars_norm, norm_pvals, y_scale)\n\n    plt.tight_layout()\n    fname = f\"bias_plots/{bias_type}_{occ}_{fname_suffix}.png\"\n    plt.savefig(fname, dpi=150)\n    plt.show()\n    plt.close()\n\n    print(f\"Saved {fname}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for occ in male_top5:\n    plot_single_occupation(\n        occ=occ,\n        bias_type=\"logit\",\n        value_col=\"mean_logit_diff\",\n        pval_col=\"p_value_logit\",\n        title_suffix=\"Logit Bias (male − female)\",\n        fname_suffix=\"logits\"\n    )\n    plot_single_occupation(\n        occ=occ,\n        bias_type=\"prob\",\n        value_col=\"mean_prob_diff\",\n        pval_col=\"p_value_prob\",\n        title_suffix=\"Probability Bias P(male) − P(female)\",\n        fname_suffix=\"probs\"\n    )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for occ in female_top5:\n    plot_single_occupation(\n        occ=occ,\n        bias_type=\"logit\",\n        value_col=\"mean_logit_diff\",\n        pval_col=\"p_value_logit\",\n        title_suffix=\"Logit Bias (male − female)\",\n        fname_suffix=\"logits\"\n    )\n    plot_single_occupation(\n        occ=occ,\n        bias_type=\"prob\",\n        value_col=\"mean_prob_diff\",\n        pval_col=\"p_value_prob\",\n        title_suffix=\"Probability Bias P(male) − P(female)\",\n        fname_suffix=\"probs\"\n    )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"similar but plots both ttest rel and 1sampttest \n# import matplotlib.pyplot as plt\n# import pandas as pd\n# import numpy as np\n# import regex as re\n# import os\n\n# os.makedirs(\"bias_plots\", exist_ok=True)\n\n# # Load the updated CSV with paired t-tests\n# occ_bias_stats = pd.read_csv(\n#     \"winobias_occupation_wise_bias_logit_prob_paired.csv\"  # Updated filename\n# )\n\n# final_layer = \"mlm_head.ln.hook_normalized\"\n# final_occ_bias = occ_bias_stats[\n#     occ_bias_stats[\"layer\"] == final_layer\n# ].copy()\n\n# # Try both diff and paired metrics for top occupations\n# final_occ_bias[\"abs_bias_diff\"] = np.abs(final_occ_bias[\"mean_logit_diff\"])\n# final_occ_bias[\"abs_bias_paired\"] = np.abs(final_occ_bias[\"mean_logit_male\"] - final_occ_bias[\"mean_logit_female\"])\n\n# male_top5_diff = (\n#     final_occ_bias[final_occ_bias[\"mean_logit_diff\"] > 0]\n#     .sort_values(\"abs_bias_diff\", ascending=False)\n#     .head(5)[\"occ_word\"].tolist()\n# )\n\n# female_top5_diff = (\n#     final_occ_bias[final_occ_bias[\"mean_logit_diff\"] < 0]\n#     .sort_values(\"abs_bias_diff\", ascending=False)\n#     .head(5)[\"occ_word\"].tolist()\n# )\n\n# male_top5_paired = (\n#     final_occ_bias[final_occ_bias[\"mean_logit_male\"] > final_occ_bias[\"mean_logit_female\"]]\n#     .sort_values(\"abs_bias_paired\", ascending=False)\n#     .head(5)[\"occ_word\"].tolist()\n# )\n\n# female_top5_paired = (\n#     final_occ_bias[final_occ_bias[\"mean_logit_male\"] < final_occ_bias[\"mean_logit_female\"]]\n#     .sort_values(\"abs_bias_paired\", ascending=False)\n#     .head(5)[\"occ_word\"].tolist()\n# )\n\n# print(\"Top 5 Male (diff):\", male_top5_diff)\n# print(\"Top 5 Female (diff):\", female_top5_diff)\n# print(\"Top 5 Male (paired):\", male_top5_paired)\n# print(\"Top 5 Female (paired):\", female_top5_paired)\n\n# def pval_column(value_col):\n#     \"\"\"Map value column to correct p-value column\"\"\"\n#     if value_col == \"mean_logit_diff\":\n#         return \"p_logit_diff\"\n#     elif value_col == \"mean_logit_male\":\n#         return \"p_logit_paired\"\n#     elif value_col == \"mean_prob_diff\":\n#         return \"p_prob_diff\"\n#     elif value_col == \"mean_prob_male\":\n#         return \"p_prob_paired\"\n#     return None\n\n# def annotate_pvals(bars, pvals, y_scale):\n#     for bar, p in zip(bars, pvals):\n#         if np.isnan(p) or p > 0.05:  # Only annotate significant p-values\n#             continue\n\n#         h = bar.get_height()\n#         offset = 0.03 * y_scale\n\n#         sig_stars = \"***\" if p < 0.001 else \"**\" if p < 0.01 else \"*\" if p < 0.05 else \"\"\n#         plt.text(\n#             bar.get_x() + bar.get_width() / 2,\n#             h + np.sign(h) * offset,\n#             sig_stars,\n#             ha=\"center\",\n#             va=\"bottom\" if h >= 0 else \"top\",\n#             fontsize=12,\n#             fontweight=\"bold\",\n#             color=\"red\"\n#         )\n\n# def layer_index(layer):\n#     if \"embed\" in layer:\n#         return -1\n#     if \"mlm_head\" in layer:\n#         return 10_000\n#     m = re.search(r\"blocks\\.(\\d+)\\.\", layer)\n#     return int(m.group(1)) if m else 9_999\n\n# def layer_short(layer):\n#     if \"embed\" in layer:\n#         return \"Emb\"\n#     if \"mlm_head\" in layer:\n#         return \"Head\"\n#     m = re.search(r\"blocks\\.(\\d+)\\.\", layer)\n#     return f\"L{m.group(1)}\" if m else layer\n\n# def hook_type(layer):\n#     if \"normalized\" in layer:\n#         return \"norm\"\n#     return \"raw\"\n\n# def plot_single_occupation(\n#     occ,\n#     bias_type,\n#     value_col,\n#     test_type,\n#     title_suffix,\n#     fname_suffix,\n# ):\n#     \"\"\"\n#     bias_type: 'logits' or 'probs'\n#     test_type: 'diff_1samp' or 'paired'\n#     \"\"\"\n#     occ_data = occ_bias_stats[occ_bias_stats[\"occ_word\"] == occ].copy()\n#     if occ_data.empty:\n#         print(f\"No data for occupation: {occ}\")\n#         return\n\n#     # Remove MLM head for probability plots\n#     if \"prob\" in value_col:\n#         occ_data = occ_data[~occ_data[\"layer\"].str.contains(\"mlm_head\")]\n\n#     occ_data[\"layer_idx\"] = occ_data[\"layer\"].apply(layer_index)\n#     occ_data[\"layer_short\"] = occ_data[\"layer\"].apply(layer_short)\n#     occ_data[\"hook\"] = occ_data[\"layer\"].apply(hook_type)\n\n#     occ_data = occ_data.sort_values(\"layer_idx\")\n\n#     layers = occ_data[\"layer_short\"].unique()\n#     x = np.arange(len(layers))\n#     width = 0.35\n\n#     raw_vals, norm_vals = [], []\n#     raw_pvals, norm_pvals = [], []\n\n#     pval_col = pval_column(value_col)\n\n#     for l in layers:\n#         raw = occ_data[\n#             (occ_data[\"layer_short\"] == l) & (occ_data[\"hook\"] == \"raw\")\n#         ]\n#         norm = occ_data[\n#             (occ_data[\"layer_short\"] == l) & (occ_data[\"hook\"] == \"norm\")\n#         ]\n\n#         raw_vals.append(raw[value_col].values[0] if len(raw) else 0.0)\n#         norm_vals.append(norm[value_col].values[0] if len(norm) else 0.0)\n\n#         raw_pvals.append(raw[pval_col].values[0] if len(raw) else np.nan)\n#         norm_pvals.append(norm[pval_col].values[0] if len(norm) else np.nan)\n\n#     raw_vals = np.array(raw_vals)\n#     norm_vals = np.array(norm_vals)\n\n#     y_scale = np.max(np.abs(np.concatenate([raw_vals, norm_vals]))) + 1e-6\n\n#     plt.figure(figsize=(12, 6))\n\n#     bars_raw = plt.bar(\n#         x - width / 2,\n#         raw_vals,\n#         width,\n#         label=\"resid_post\",\n#         alpha=0.8,\n#         edgecolor=\"black\",\n#         color=\"skyblue\"\n#     )\n\n#     bars_norm = plt.bar(\n#         x + width / 2,\n#         norm_vals,\n#         width,\n#         label=\"resid_post_norm\",\n#         alpha=0.8,\n#         edgecolor=\"black\",\n#         color=\"salmon\"\n#     )\n\n#     plt.axhline(0, color=\"black\", linewidth=1.5)\n#     plt.xticks(x, layers, rotation=45)\n    \n#     ylabel = \"Logit Diff\" if \"logit\" in value_col else \"Prob Diff\"\n#     plt.ylabel(ylabel)\n#     plt.xlabel(\"Layer\")\n\n#     test_label = \"1-sample t-test\\ndiff≠0\" if test_type == \"diff_1samp\" else \"Paired t-test\\nmale≠female\"\n#     plt.title(f\"{occ} ({bias_type} | {test_label})\\n{title_suffix}\", fontsize=13)\n#     plt.legend()\n\n#     annotate_pvals(bars_raw, raw_pvals, y_scale)\n#     annotate_pvals(bars_norm, norm_pvals, y_scale)\n\n#     plt.tight_layout()\n#     fname = f\"bias_plots/{bias_type}_{test_type}_{occ}_{fname_suffix}.png\"\n#     plt.savefig(fname, dpi=150, bbox_inches='tight')\n#     plt.show()\n#     plt.close()\n\n#     print(f\"Saved {fname}\")\n\n# # Generate plots for both test types and top occupations\n# top_occupations = list(set(male_top5_diff + female_top5_diff + male_top5_paired + female_top5_paired))[:10]\n\n# for occ in top_occupations:\n#     # Logit plots - both test types\n#     # plot_single_occupation(occ, \"logits\", \"mean_logit_diff\", \"diff_1samp\", \n#     #                       \"1-sample t-test on logit(male)-logit(female)\", \"logits_diff\")\n#     plot_single_occupation(occ, \"logits\", \"mean_logit_male\", \"paired\", \n#                           \"Paired t-test logit(male) vs logit(female)\", \"logits_paired\")\n    \n#     # Probability plots - both test types  \n#     # plot_single_occupation(occ, \"probs\", \"mean_prob_diff\", \"diff_1samp\", \n#     #                       \"1-sample t-test on prob(male)-prob(female)\", \"probs_diff\")\n#     plot_single_occupation(occ, \"probs\", \"mean_prob_male\", \"paired\", \n#                           \"Paired t-test prob(male) vs prob(female)\", \"probs_paired\")\n\n# print(\"✅ All paired t-test plots generated!\")\n# print(\"Check bias_plots/ directory for results.\")\n","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import pandas as pd\n# import numpy as np\n# import regex as re\n# import os\n\n# os.makedirs(\"bias_plots\", exist_ok=True)\n\n# # Load the updated CSV with paired t-tests\n# occ_bias_stats = pd.read_csv(\n#     \"winobias_occupation_wise_bias_logit_prob_paired.csv\"\n# )\n\n# final_layer = \"mlm_head.ln.hook_normalized\"\n# final_occ_bias = occ_bias_stats[\n#     occ_bias_stats[\"layer\"] == final_layer\n# ].copy()\n\n# final_occ_bias[\"abs_bias_paired\"] = np.abs(final_occ_bias[\"mean_logit_male\"] - final_occ_bias[\"mean_logit_female\"])\n\n# male_top5_paired = (\n#     final_occ_bias[final_occ_bias[\"mean_logit_male\"] > final_occ_bias[\"mean_logit_female\"]]\n#     .sort_values(\"abs_bias_paired\", ascending=False)\n#     .head(5)[\"occ_word\"].tolist()\n# )\n\n# female_top5_paired = (\n#     final_occ_bias[final_occ_bias[\"mean_logit_male\"] < final_occ_bias[\"mean_logit_female\"]]\n#     .sort_values(\"abs_bias_paired\", ascending=False)\n#     .head(5)[\"occ_word\"].tolist()\n# )\n\n# print(\"Top 5 Male (paired):\", male_top5_paired)\n# print(\"Top 5 Female (paired):\", female_top5_paired)\n\n# def layer_index(layer):\n#     if \"embed\" in layer:\n#         return -1\n#     if \"mlm_head\" in layer:\n#         return 10_000\n#     m = re.search(r\"blocks\\.(\\d+)\\.\", layer)\n#     return int(m.group(1)) if m else 9_999\n\n# def layer_short(layer):\n#     if \"embed\" in layer:\n#         return \"Emb\"\n#     if \"mlm_head\" in layer:\n#         return \"Head\"\n#     m = re.search(r\"blocks\\.(\\d+)\\.\", layer)\n#     return f\"L{m.group(1)}\" if m else layer\n\n# def hook_type(layer):\n#     if \"normalized\" in layer:\n#         return \"norm\"\n#     return \"raw\"\n\n# def plot_paired_occupation(\n#     occ,\n#     bias_type,\n#     title_suffix,\n#     fname_suffix,\n# ):\n#     \"\"\"\n#     Plot PAIRED t-test results: Male vs Female logits/probs side-by-side per layer\n#     4 bars per layer + 2 p-values per layer (one per hook)\n#     \"\"\"\n#     occ_data = occ_bias_stats[occ_bias_stats[\"occ_word\"] == occ].copy()\n#     if occ_data.empty:\n#         print(f\"No data for occupation: {occ}\")\n#         return\n\n#     # Remove MLM head for probability plots\n#     if bias_type == \"probs\":\n#         occ_data = occ_data[~occ_data[\"layer\"].str.contains(\"mlm_head\")]\n\n#     occ_data[\"layer_idx\"] = occ_data[\"layer\"].apply(layer_index)\n#     occ_data[\"layer_short\"] = occ_data[\"layer\"].apply(layer_short)\n#     occ_data[\"hook\"] = occ_data[\"layer\"].apply(hook_type)\n\n#     occ_data = occ_data.sort_values(\"layer_idx\")\n\n#     layers = occ_data[\"layer_short\"].unique()\n#     x = np.arange(len(layers))\n#     width = 0.18\n\n#     # Value columns for paired test\n#     if bias_type == \"logits\":\n#         male_col, female_col = \"mean_logit_male\", \"mean_logit_female\"\n#         pval_col = \"p_logit_paired\"\n#         ylabel = \"Logits\"\n#     else:  # probs\n#         male_col, female_col = \"mean_prob_male\", \"mean_prob_female\"\n#         pval_col = \"p_prob_paired\"\n#         ylabel = \"Probabilities\"\n\n#     raw_male_vals, raw_female_vals = [], []\n#     norm_male_vals, norm_female_vals = [], []\n#     raw_pvals, norm_pvals = [], []\n\n#     for l in layers:\n#         # Raw layer\n#         raw = occ_data[(occ_data[\"layer_short\"] == l) & (occ_data[\"hook\"] == \"raw\")]\n#         raw_male_vals.append(raw[male_col].values[0] if len(raw) else 0.0)\n#         raw_female_vals.append(raw[female_col].values[0] if len(raw) else 0.0)\n#         raw_pvals.append(raw[pval_col].values[0] if len(raw) else np.nan)\n        \n#         # Norm layer\n#         norm = occ_data[(occ_data[\"layer_short\"] == l) & (occ_data[\"hook\"] == \"norm\")]\n#         norm_male_vals.append(norm[male_col].values[0] if len(norm) else 0.0)\n#         norm_female_vals.append(norm[female_col].values[0] if len(norm) else 0.0)\n#         norm_pvals.append(norm[pval_col].values[0] if len(norm) else np.nan)\n\n#     # Convert to arrays\n#     raw_male_vals = np.array(raw_male_vals)\n#     raw_female_vals = np.array(raw_female_vals)\n#     norm_male_vals = np.array(norm_male_vals)\n#     norm_female_vals = np.array(norm_female_vals)\n#     raw_pvals = np.array(raw_pvals)\n#     norm_pvals = np.array(norm_pvals)\n\n#     y_scale = np.max(np.abs(np.concatenate([raw_male_vals, raw_female_vals, norm_male_vals, norm_female_vals]))) + 1e-6\n\n#     plt.figure(figsize=(14, 7))\n\n#     # 4 bars per layer\n#     bars_raw_male = plt.bar(x - 1.5*width, raw_male_vals, width, \n#                            label=\"Male (resid_post)\", alpha=0.8, \n#                            edgecolor=\"black\", color=\"skyblue\")\n#     bars_raw_female = plt.bar(x - 0.5*width, raw_female_vals, width, \n#                              label=\"Female (resid_post)\", alpha=0.8, \n#                              edgecolor=\"black\", color=\"lightcoral\")\n#     bars_norm_male = plt.bar(x + 0.5*width, norm_male_vals, width, \n#                             label=\"Male (resid_post_norm)\", alpha=0.8, \n#                             edgecolor=\"black\", color=\"steelblue\")\n#     bars_norm_female = plt.bar(x + 1.5*width, norm_female_vals, width, \n#                               label=\"Female (resid_post_norm)\", alpha=0.8, \n#                               edgecolor=\"black\", color=\"salmon\")\n\n#     plt.axhline(0, color=\"black\", linewidth=1.5)\n#     plt.xticks(x, layers, rotation=45)\n#     plt.ylabel(ylabel)\n#     plt.xlabel(\"Layer\")\n#     plt.title(f\"{occ} ({bias_type} | Paired t-test: Male vs Female)\\n{title_suffix}\", fontsize=14)\n#     plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n\n#     # Annotate 2 p-values per layer: one for raw (above raw male), one for norm (above norm male)\n#     for i in range(len(layers)):\n#         # Raw p-value (above raw male bar)\n#         if not np.isnan(raw_pvals[i]):\n#             h_raw = np.max([raw_male_vals[i], raw_female_vals[i]])  # Above highest raw bar\n#             plt.text(\n#                 x[i] - width,  # Center of raw male bar\n#                 h_raw + 0.015 * y_scale,\n#                 f\"p={raw_pvals[i]:.3f}\",\n#                 ha=\"center\",\n#                 va=\"bottom\",\n#                 fontsize=9,\n#                 fontweight=\"bold\",\n#                 rotation=45  # Slanted text\n#             )\n        \n#         # Norm p-value (above norm male bar)\n#         if not np.isnan(norm_pvals[i]):\n#             h_norm = np.max([norm_male_vals[i], norm_female_vals[i]])  # Above highest norm bar\n#             plt.text(\n#                 x[i] + width,  # Center of norm male bar\n#                 h_norm + 0.015 * y_scale,\n#                 f\"p={norm_pvals[i]:.3f}\",\n#                 ha=\"center\",\n#                 va=\"bottom\",\n#                 fontsize=9,\n#                 fontweight=\"bold\",\n#                 rotation=45  # Slanted text\n#             )\n\n#     plt.tight_layout()\n#     fname = f\"bias_plots/{bias_type}_paired_4bar_{occ}_{fname_suffix}.png\"\n#     plt.savefig(fname, dpi=150, bbox_inches='tight')\n#     plt.show()\n#     plt.close()\n\n#     print(f\"Saved {fname}\")\n\n# # Generate plots for top occupations\n# top_occupations = list(set(male_top5_paired + female_top5_paired))[:10]\n\n# for occ in top_occupations:\n#     plot_paired_occupation(occ, \"logits\", \n#                           \"Paired t-test per hook: Male vs Female logits\", \"logits\")\n#     plot_paired_occupation(occ, \"probs\", \n#                           \"Paired t-test per hook: Male vs Female probs\", \"probs\")\n\n\n# print(\"Check bias_plots/ directory for results.\")\n","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## permutation test for logit based occupaton wise gender bias\n\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom scipy.stats import permutation_test\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ndef permutation_test_bias(analysis_df, occ_word, layer, bias_type='logits', n_permutations=5000, seed=42):\n    \"\"\"\n    WEAT-style permutation test for occupation bias.\n    \"\"\"\n    np.random.seed(seed)\n    \n    layer_df = analysis_df[(analysis_df[\"occ_word\"] == occ_word) & (analysis_df[\"layer\"] == layer)]\n    \n    if len(layer_df) < 4:\n        return {'p_perm': np.nan, 'test_stat': np.nan, 'n_samples': 0,\n                'mean_male': np.nan, 'mean_female': np.nan}\n    \n    if bias_type == 'logits':\n        male_vals = layer_df[\"logit_male\"].dropna().values\n        female_vals = layer_df[\"logit_female\"].dropna().values\n    else:\n        male_vals = layer_df[\"prob_male\"].dropna().values\n        female_vals = layer_df[\"prob_female\"].dropna().values\n    \n    n_male, n_female = len(male_vals), len(female_vals)\n    n_samples = n_male + n_female\n    \n    if n_male < 2 or n_female < 2:\n        return {'p_perm': np.nan, 'test_stat': np.nan, 'n_samples': n_samples,\n                'mean_male': np.mean(male_vals) if n_male else np.nan,\n                'mean_female': np.mean(female_vals) if n_female else np.nan}\n    \n    observed_stat = np.mean(male_vals) - np.mean(female_vals)\n    \n    # Efficient vectorized permutations\n    permuted_stats = np.zeros(n_permutations)\n    all_data = np.concatenate([male_vals, female_vals])\n    \n    for i in range(n_permutations):\n        np.random.shuffle(all_data)\n        perm_male = all_data[:n_male]\n        perm_female = all_data[n_male:]\n        permuted_stats[i] = np.mean(perm_male) - np.mean(perm_female)\n    \n    # Two-tailed p-value\n    p_value = np.mean(np.abs(permuted_stats) >= np.abs(observed_stat))\n    \n    return {\n        'p_perm': p_value,\n        'test_stat': observed_stat,\n        'n_samples': n_samples,\n        'n_male': n_male,\n        'n_female': n_female,\n        'mean_male': np.mean(male_vals),\n        'mean_female': np.mean(female_vals),\n        'perm_std': np.std(permuted_stats)\n    }\n\ndef occupation_permutation_stats(analysis_df, layers_of_interest=None, n_permutations=5000):\n    \"\"\"\n    Sequential version - no multiprocessing issues\n    \"\"\"\n    if layers_of_interest is None:\n        layers_of_interest = analysis_df[\"layer\"].unique()\n    \n    results = []\n    unique_combos = analysis_df[[\"occ_word\", \"layer\"]].drop_duplicates()\n    \n    print(f\"Processing {len(unique_combos)} occupation-layer combos...\")\n    \n    for idx, (occ_word, layer) in enumerate(unique_combos.itertuples(index=False)):\n        if idx % 50 == 0:\n            print(f\"Progress: {idx}/{len(unique_combos)} ({idx/len(unique_combos)*100:.1f}%)\")\n        \n        # Logits\n        logit_results = permutation_test_bias(analysis_df, occ_word, layer, 'logits', n_permutations)\n        logit_results.update({'layer': layer, 'occ_word': occ_word, 'bias_type': 'logits'})\n        results.append(logit_results)\n        \n        # Probs\n        prob_results = permutation_test_bias(analysis_df, occ_word, layer, 'probs', n_permutations)\n        prob_results.update({'layer': layer, 'occ_word': occ_word, 'bias_type': 'probs'})\n        results.append(prob_results)\n    \n    results_df = pd.DataFrame(results)\n    print(\"✅ Permutation tests complete!\")\n    return results_df\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Running permutation tests...\")\nperm_stats = occupation_permutation_stats(analysis_df, n_permutations=2000)  \nperm_stats.to_csv(\"winobias_permutation_test_results.csv\", index=False)\n\nprint(\"\\n=== TOP 10 MALE-BIASED LOGITS (PERMUTATION TEST) ===\")\nlogit_perm = perm_stats[(perm_stats['bias_type']=='logits')]\nprint(logit_perm.nlargest(10, 'test_stat')[\n    ['occ_word', 'layer', 'test_stat', 'p_perm', 'n_samples', 'mean_male', 'mean_female']\n].round(4))\n\nprint(\"\\n=== TOP 10 FEMALE-BIASED LOGITS ===\")\nfemale_bias = logit_perm.nsmallest(10, 'test_stat')\nprint(logit_perm.nsmallest(10, 'test_stat')[\n    ['occ_word', 'layer', 'test_stat', 'p_perm', 'n_samples', 'mean_male', 'mean_female']\n].round(4))\n\n# Compare with t-test p-values \nif 'occ_bias_stats' in globals():\n    final_layer = \"mlm_head.ln.hook_normalized\"\n    comparison = occ_bias_stats[occ_bias_stats[\"layer\"] == final_layer].merge(\n        perm_stats[(perm_stats['layer']==final_layer) & (perm_stats['bias_type']=='logits')],\n        on=['layer', 'occ_word']\n    )\n    print(\"\\n=== T-TEST vs PERMUTATION (Final Layer) ===\")\n    print(comparison.nlargest(10, 'test_stat')[\n        ['occ_word', 'mean_logit_male', 'p_logit_paired', 'p_perm']\n    ].round(4))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}